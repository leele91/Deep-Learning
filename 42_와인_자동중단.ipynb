{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "42_와인_자동중단.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhSV4xlLhkEo0mTNPb9W4y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leele91/Deep-Learning/blob/main/42_%EC%99%80%EC%9D%B8_%EC%9E%90%EB%8F%99%EC%A4%91%EB%8B%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB7sPumUY6zB"
      },
      "source": [
        "# 와인 베스트 모델 찾은 후 자동중단"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km3PV07vl8i5",
        "outputId": "ddc04ea1-8a8a-4579-d882-19cedb20a6ea"
      },
      "source": [
        "# !rm -rf model\r\n",
        "!ls -l"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 716\n",
            "drwxr-xr-x 1 root root   4096 Feb  4 15:26  sample_data\n",
            "-rw-r--r-- 1 root root 361279 Feb 10 01:14 'wine (1).csv'\n",
            "-rw-r--r-- 1 root root 361279 Feb 10 00:45  wine.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zWESxrqY1ob"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTnUBpV6ZLe5"
      },
      "source": [
        "# 실행할 때마다 같은 결과를 출력하기 위한 seed 값 설정\r\n",
        "seed =2021\r\n",
        "np.random.seed(seed)\r\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsKxZ05oZUBR"
      },
      "source": [
        "###  데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "z4nAiiGyZTgq",
        "outputId": "931aff9c-8bc2-44eb-ec36-70d170659620"
      },
      "source": [
        "# 준비된 수술 환자 데이터를 불러들임\r\n",
        "from google.colab import files\r\n",
        "uploaded = files.upload()\r\n",
        "filename = list(uploaded.keys())[0]\r\n",
        "filename"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-32aed6c0-3115-4a25-8aeb-7fa949e0a725\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-32aed6c0-3115-4a25-8aeb-7fa949e0a725\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving wine.csv to wine (2).csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'wine.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "jNRlm0EZZnwv",
        "outputId": "ad3d2ad5-456e-40e2-f8db-15c42808d337"
      },
      "source": [
        "import pandas as pd\r\n",
        "df = pd.read_csv(filename, header=None)\r\n",
        "df.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0     1     2    3      4     5     6       7     8     9    10  11  12\n",
              "0  7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1\n",
              "1  7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8   5   1\n",
              "2  7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8   5   1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXUtZoTpZ37Z",
        "outputId": "271a50ea-8436-444d-f4fe-173c8398318d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(\r\n",
        "    df.iloc[:, :-1].values, df.iloc[:, -1].values, stratify=df.iloc[:, -1].values,\r\n",
        "    random_state=seed\r\n",
        ")\r\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4872, 12), (1625, 12))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e0c9bv3a2-6"
      },
      "source": [
        "### 모델 정의/설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqGrbcgRamKZ"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqsOCqI2bER8",
        "outputId": "00110c5e-c8a0-45ed-a454-6040675203cd"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Dense(30, input_dim=12, activation='relu'))\r\n",
        "model.add(Dense(12, activation='relu'))\r\n",
        "model.add(Dense(8, activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 30)                390       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12)                372       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 875\n",
            "Trainable params: 875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxxoqMdMbsdu"
      },
      "source": [
        "# 모델 컴파일 \r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPI19Z6ub3X1"
      },
      "source": [
        "### 모델 저장 관련 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-NMKqvfbzu0"
      },
      "source": [
        "import os\r\n",
        "MODEL_DIR = './model/'\r\n",
        "if not os.path.exists(MODEL_DIR):\r\n",
        "    os.mkdir(MODEL_DIR)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyNSuDXWcJlE",
        "outputId": "e519ba4f-f57d-4f98-b986-ce1ed9cf639b"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1076\n",
            "drwxr-xr-x 2 root root   4096 Feb 10 01:41  model\n",
            "drwxr-xr-x 1 root root   4096 Feb  4 15:26  sample_data\n",
            "-rw-r--r-- 1 root root 361279 Feb 10 01:14 'wine (1).csv'\n",
            "-rw-r--r-- 1 root root 361279 Feb 10 01:40 'wine (2).csv'\n",
            "-rw-r--r-- 1 root root 361279 Feb 10 00:45  wine.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCoBEfpNcLH9"
      },
      "source": [
        "# 모델 저장 조건 설정\r\n",
        "modelpath = MODEL_DIR + \"best{epoch:03d}-{val_loss:.4f}.hdf5\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFlulTj-cjWX"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\r\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \r\n",
        "                               verbose=1, save_best_only=True)\r\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=30)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IjnHhkgdTSi"
      },
      "source": [
        "### 모델 학습 및 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLW102LudPGw",
        "outputId": "1baad8d0-a141-467c-a4e7-fee56b493c05"
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=200, batch_size=200,\r\n",
        "          verbose=0, callbacks=[checkpointer, early_stopping_callback])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.41822, saving model to ./model/best001-0.4182.hdf5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.41822 to 0.28623, saving model to ./model/best002-0.2862.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.28623 to 0.24628, saving model to ./model/best003-0.2463.hdf5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.24628 to 0.22050, saving model to ./model/best004-0.2205.hdf5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.22050 to 0.20001, saving model to ./model/best005-0.2000.hdf5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.20001 to 0.19209, saving model to ./model/best006-0.1921.hdf5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.19209 to 0.18488, saving model to ./model/best007-0.1849.hdf5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.18488 to 0.18360, saving model to ./model/best008-0.1836.hdf5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.18360 to 0.17670, saving model to ./model/best009-0.1767.hdf5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.17670 to 0.17541, saving model to ./model/best010-0.1754.hdf5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.17541 to 0.17388, saving model to ./model/best011-0.1739.hdf5\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.17388 to 0.16688, saving model to ./model/best012-0.1669.hdf5\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.16688 to 0.16274, saving model to ./model/best013-0.1627.hdf5\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.16274 to 0.16253, saving model to ./model/best014-0.1625.hdf5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.16253 to 0.15751, saving model to ./model/best015-0.1575.hdf5\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.15751 to 0.15722, saving model to ./model/best016-0.1572.hdf5\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.15722 to 0.15508, saving model to ./model/best017-0.1551.hdf5\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.15508 to 0.15077, saving model to ./model/best018-0.1508.hdf5\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.15077 to 0.14924, saving model to ./model/best019-0.1492.hdf5\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.14924 to 0.14708, saving model to ./model/best020-0.1471.hdf5\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.14708 to 0.14639, saving model to ./model/best021-0.1464.hdf5\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.14639\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.14639 to 0.13917, saving model to ./model/best023-0.1392.hdf5\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.13917 to 0.13772, saving model to ./model/best024-0.1377.hdf5\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.13772 to 0.13441, saving model to ./model/best025-0.1344.hdf5\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.13441 to 0.12824, saving model to ./model/best026-0.1282.hdf5\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.12824 to 0.12421, saving model to ./model/best027-0.1242.hdf5\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.12421\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.12421\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.12421\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.12421 to 0.11388, saving model to ./model/best031-0.1139.hdf5\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.11388 to 0.10927, saving model to ./model/best032-0.1093.hdf5\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.10927 to 0.10697, saving model to ./model/best033-0.1070.hdf5\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.10697 to 0.10434, saving model to ./model/best034-0.1043.hdf5\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.10434\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.10434\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.10434 to 0.10397, saving model to ./model/best037-0.1040.hdf5\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.10397 to 0.10336, saving model to ./model/best038-0.1034.hdf5\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.10336\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.10336\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.10336 to 0.09690, saving model to ./model/best041-0.0969.hdf5\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.09690\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.09690\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.09690 to 0.09461, saving model to ./model/best044-0.0946.hdf5\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.09461\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.09461 to 0.09151, saving model to ./model/best046-0.0915.hdf5\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.09151\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.09151 to 0.09145, saving model to ./model/best048-0.0914.hdf5\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.09145 to 0.08915, saving model to ./model/best049-0.0891.hdf5\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.08915\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.08915\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.08915 to 0.08568, saving model to ./model/best052-0.0857.hdf5\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.08568 to 0.08503, saving model to ./model/best053-0.0850.hdf5\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.08503 to 0.08463, saving model to ./model/best054-0.0846.hdf5\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.08463\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.08463 to 0.08397, saving model to ./model/best056-0.0840.hdf5\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.08397\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.08397 to 0.08135, saving model to ./model/best058-0.0813.hdf5\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.08135 to 0.07926, saving model to ./model/best059-0.0793.hdf5\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.07926\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.07926\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.07926 to 0.07745, saving model to ./model/best062-0.0774.hdf5\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.07745\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.07745\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.07745 to 0.07615, saving model to ./model/best065-0.0761.hdf5\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.07615\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.07615\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.07615\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.07615 to 0.07327, saving model to ./model/best069-0.0733.hdf5\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.07327\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.07327\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.07327 to 0.07200, saving model to ./model/best072-0.0720.hdf5\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.07200\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.07200 to 0.07014, saving model to ./model/best074-0.0701.hdf5\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.07014\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.07014 to 0.06874, saving model to ./model/best076-0.0687.hdf5\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.06874\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.06874\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.06874\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.06874\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.06874 to 0.06720, saving model to ./model/best081-0.0672.hdf5\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.06720\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.06720 to 0.06626, saving model to ./model/best083-0.0663.hdf5\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.06626\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.06626 to 0.06570, saving model to ./model/best085-0.0657.hdf5\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.06570\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.06570\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.06570\n",
            "\n",
            "Epoch 00089: val_loss improved from 0.06570 to 0.06368, saving model to ./model/best089-0.0637.hdf5\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.06368 to 0.06190, saving model to ./model/best098-0.0619.hdf5\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.06190\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.06190\n",
            "\n",
            "Epoch 00101: val_loss improved from 0.06190 to 0.06155, saving model to ./model/best101-0.0615.hdf5\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.06155\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.06155\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.06155\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.06155 to 0.06092, saving model to ./model/best105-0.0609.hdf5\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.06092\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.06092\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.06092\n",
            "\n",
            "Epoch 00109: val_loss improved from 0.06092 to 0.05978, saving model to ./model/best109-0.0598.hdf5\n",
            "\n",
            "Epoch 00110: val_loss improved from 0.05978 to 0.05942, saving model to ./model/best110-0.0594.hdf5\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00121: val_loss improved from 0.05942 to 0.05878, saving model to ./model/best121-0.0588.hdf5\n",
            "\n",
            "Epoch 00122: val_loss improved from 0.05878 to 0.05850, saving model to ./model/best122-0.0585.hdf5\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.05850\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.05850 to 0.05748, saving model to ./model/best124-0.0575.hdf5\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.05748\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.05748\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.05748\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.05748\n",
            "\n",
            "Epoch 00129: val_loss improved from 0.05748 to 0.05742, saving model to ./model/best129-0.0574.hdf5\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.05742\n",
            "\n",
            "Epoch 00131: val_loss improved from 0.05742 to 0.05704, saving model to ./model/best131-0.0570.hdf5\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.05704\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.05704\n",
            "\n",
            "Epoch 00134: val_loss improved from 0.05704 to 0.05617, saving model to ./model/best134-0.0562.hdf5\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.05617\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.05617\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.05617\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.05617\n",
            "\n",
            "Epoch 00139: val_loss improved from 0.05617 to 0.05568, saving model to ./model/best139-0.0557.hdf5\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.05568\n",
            "\n",
            "Epoch 00141: val_loss improved from 0.05568 to 0.05566, saving model to ./model/best141-0.0557.hdf5\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.05566\n",
            "\n",
            "Epoch 00156: val_loss improved from 0.05566 to 0.05539, saving model to ./model/best156-0.0554.hdf5\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.05539\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.05539\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.05539\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.05539\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.05539\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.05539\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.05539\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.05539\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.05539\n",
            "\n",
            "Epoch 00166: val_loss improved from 0.05539 to 0.05447, saving model to ./model/best166-0.0545.hdf5\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.05447\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.05447\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.05447\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.05447\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.05447\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.05447\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.05447\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.05447\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.05447\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.05447\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.05447\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.05447\n",
            "\n",
            "Epoch 00179: val_loss improved from 0.05447 to 0.05391, saving model to ./model/best179-0.0539.hdf5\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.05391\n",
            "\n",
            "Epoch 00181: val_loss improved from 0.05391 to 0.05305, saving model to ./model/best181-0.0530.hdf5\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.05305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TFV7vIdeUZl"
      },
      "source": [
        "### 잘못된 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqhHINwzdy4-",
        "outputId": "e82e26c6-f4c3-4053-9fb3-32e556636f8a"
      },
      "source": [
        "acc = model.evaluate(X_test, y_test)\r\n",
        "print(f'Accuracy: {acc[1]:.4f}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9791\n",
            "Accuracy: 0.9791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQDhsxwekSd"
      },
      "source": [
        "### 베스트 모델로 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdbez_CVehyj",
        "outputId": "411e769b-dc53-43f9-d4f3-f3eccbb2a688"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n",
        "best_model = load_model('./model/best181-0.0530.hdf5')\r\n",
        "acc = best_model.evaluate(X_test, y_test)\r\n",
        "print(f'Accuracy: {acc[1]:.4f}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9778\n",
            "Accuracy: 0.9778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE1R9Ml3gZP7"
      },
      "source": [
        "### 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mwCltZRfXrq"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geH-GLqsgjMm",
        "outputId": "72e6a54b-4002-454c-dc47-f2b3958015fc"
      },
      "source": [
        "# history = model.fit(X_train, y_train, validation_split=0.2, epochs=200, batch_size=200,\r\n",
        "#           verbose=0, callbacks=[checkpointer])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.05065\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.05065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhqfsIuTgzep",
        "outputId": "89256393-07a3-47bb-ccc6-22a8ae52dbda"
      },
      "source": [
        "type(history.history)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1YvLJqdhB62"
      },
      "source": [
        "y_vloss = history.history['val_loss']\r\n",
        "y_acc = history.history['accuracy']\r\n",
        "y_vacc = history.history['val_accuracy']\r\n",
        "y_loss = history.history['loss']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "l2y7lBtehVNl",
        "outputId": "87ace03c-6e0a-418d-8cbe-039bd80d4529"
      },
      "source": [
        "x_len = np.arange(len(y_acc))\r\n",
        "plt.figure(figsize=(12,8))\r\n",
        "plt.plot(x_len, y_loss, \"o\", c=\"red\", markersize=2, label= 'loss')\r\n",
        "plt.plot(x_len, y_vacc, \"o\", c=\"blue\", markersize=2, label= 'vacc')\r\n",
        "plt.plot(x_len, y_vloss, \"o\", c=\"orange\", markersize=2, label= 'vloss')\r\n",
        "plt.plot(x_len, y_acc, \"o\", c=\"green\", markersize=2, label= 'acc')\r\n",
        "plt.grid()\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV4z3hwdiFZc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}